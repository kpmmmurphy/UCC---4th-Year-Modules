
\iffalse
\documentclass{article}
\fi

\documentclass[a4paper,10pt]{article}

\newenvironment{proof}{\par \noindent {\bf Proof:}}{\begin{flushright}$\Box$\end{flushright}\par \noindent}
\newtheorem{theorem}{\bf Theorem}
\newtheorem{definition}[theorem]{\bf Definition}
\newtheorem{lemma}{\bf Lemma}
\newtheorem{corollary}[theorem]{\bf Corollary}
\newcommand{\pari}{\hspace{\parindent}}

\usepackage{graphicx}

\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{float}
\usepackage{titlepic}
\usepackage{listings}
\usepackage{color}
\usepackage{array}
\usepackage{varwidth}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=5mm,
  belowskip=5mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=false,
  breakatwhitespace=true,
  tabsize=2
}

\usepackage[margin=1.3in,bottom=1in,top=1in]{geometry}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\usepackage{fix-cm}
\newcommand{\bigsize}{\fontsize{24pt}{20pt}\selectfont}
\newcommand{\meiumsize}{\fontsize{16pt}{20pt}\selectfont}

\begin{document}

\begin{titlepage}

\centering
\includegraphics[width=\textwidth]{"header".jpg}

\vspace{2cm}
{\bigsize \textbf{Automated Safety and Security System for the Home}}
\vspace{2cm}

\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{ R{5cm} c } 

 {\meiumsize \textbf{Student Name:}} & {\meiumsize Kevin Patrick Murphy}
 \\\
 {\meiumsize \textbf{Student ID:}} & {\meiumsize 111314826} 
 \\\\\\\
 {\meiumsize \textbf{Supervisor:}} & {\meiumsize Professor Cormac J. Sreenan} 
 \\\
 {\meiumsize \textbf{Second Reader:}} & {\meiumsize Professor John Morrison}
 
\end{tabular}
\end{center}
\end{table}

\vspace{2cm}

\begin{center}
{\meiumsize B. Sc. Final Year Project Report}\\
\vspace{1cm}
{\meiumsize 2015}\\
\end{center}

\end{titlepage}

\section*{Declaration of Originality}
In signing this declaration, you are confirming, in writing, that the submitted work is entirely your own original work, except where clearly attributed otherwise, and that it has not been submitted partly or wholly for any other educational award.\\\\
I hereby declare that :
\begin{itemize}
  \item This is all my own work, unless clearly indicated otherwise, with full and proper accreditation;
  \item With respect to my own work: none of it has been submitted at any educational institution contributing in any way towards an educational award
  \item with respect to another\rq s work: all text, diagrams, code, or ideas, whether verbatim, paraphrased or otherwise modified or adapted, have been duly attributed to the source in a scholarly manner, whether from books, papers, lecture notes or any other student\rq s work, whether published or unpublished, electronically or in print.  \ldots
\end{itemize}

\begin{table}[H]
\def\arraystretch{2}% 
 \begin{tabular}{ R{5cm} c } 

 {\meiumsize \textbf{Name:}} & {\meiumsize Kevin Patrick Murphy}
 \\\
 {\meiumsize \textbf{Signed:}} & {\meiumsize } 
 \\\
 {\meiumsize \textbf{Date:}} & {\meiumsize }
 
\end{tabular}
\end{table}

\newpage
\section*{Acknowledgments}
I would like to thank Professor Cormac J. Sreenan for supervising this project, and for providing invaluable guidence throughout its duration. I would also like to thank my family for their everlasting support. 


\newpage
\begin{abstract}

{\ 
The investigation, design and implementation of a distributed system for monitoring and controlling safety-related sensors in the home. By leveraging the areas of embedded computing, mobile applications development and server side development, the creation of a full software ecosystem was undertaken. Close attention was devoted to the software and hardware architecture required to provide optimal supporting infrastructure for the system. Configuration, communication, and alerting are the core problems addressed.

The final system is comprised of four components.  At the core of the architecture sits the Sensor Management System, orchestrating all sensor interaction. Each subsystem is designed to utilise or facilitate its operation. An Android mobile application forms the user interface for the system, and provides live sensor data, camera operation, data graphing, configuration and push notification alerting. 
Cloud integration to achieve remote management and operation was introduced via a Representational State Transfer server side application programming interface. 

An additional Peripheral Sensing System was included in the final implementation to provide remote monitoring. This acts as a scaled down version of the core Sensor Management System, with all  communication between sensing systems taking place wirelessly.  

At the core of each subsystem is a middleware layer providing JSON message passing services, linking all entities together. Direct communication is facilitated via the Android application, and the Sensor Management System. }

\end{abstract}

\newpage

\tableofcontents

\newpage

\section{Introduction}
The ceiling in my kitchen is 7 feet tall, and with little ventilation, steam and smoke accumulate rapidly. This results in the smoke alarm being triggering numerous times each evening. To overcome this problem, while cooking, the batteries in the alarm are removed, and replaced when finished. However, in the event of someone forgetting to replace the batteries, there is virtually no means of alerting if a fire does occur. This began the initial conceptualization for this project. \\\\
The simplistic functionality of the smoke alarm left much to be desired. I started to devise an embedded sensor system solution that would allow complete control over alerting functionality. This lead to further ideas on how to control and manage the integrated sensors, or more specifically, giving the user the ability to configure them as required. \\\\
The main question I then asked myself was: how can safety and security be improve within the home, through the leveraging of modern hardware and software components? I kept this question in mind throughout the entire project lifecycle.

\subsection{Background}
Previous to starting the project I have no experience working with embedded systems, or electronics in general. Creating the circuit at the beginning of the project was one of the most challenging aspects I had to face. Without a reliable hardware implementation, the system is rendered completely futile.\\\\
Python is fastly growing as a popular multi-purpose language. It is used right across the IT spectrum, from machine learning to web development. I had never written a single line of Python before the project started, and wanted to acquire a working knowledge of the language before leaving university. \\\\
Similarly, I had only written minimal C programs previous to the project. As C++ is used for high performance programming in many areas, I wanted to gain some experience in developing with it. While the amount of C++ code in the project is small, I got to learn the basic principles of C++ development. \\\\
I had experimented with the Raspberry Pi a number of times over the last two years, but not for software development. I had previously employed it as a home media center solution. As for the Intel Galileo, I had never come into contact with one. I also had no experience with the Arduino board, so development with the Galileo started at a slow pace.  \\\\
My work placement was spent at a mobile applications development company, where I worked as an Android developer. I was comfortable with the basic APIs available, but as a new version of the Android operating system was released around November of 2014, I wanted to gain experience with its new features and UI styles. 

\newpage
\section{Problem Analysis}
\subsection{The Internet of Things}
The Internet of Things(IoT) is the term used to describe the ever increasing number of networked devices and appliances in the world around us. Employing embedded systems with networking capabilities has opened a range of opportunities, both within and outside of the home. These devices can be remotely monitored, controlled, and configured, offering ultimate freedom of how they are utilised. \\\\
Newfound levels of automation can be achieved through the creation of intelligent systems which can learn from the vast amounts of data generated by these devices. This generated data can be used in a multitude of ways, such as to provide insightful feedback, or improve operation. The application of these systems can be seen in problem areas stretching from environmental monitoring and energy management, to air and road traffic control. 

\subsection{Current Safety Applications}
Safety applications are becoming more prevalent in the home and in industry. Irish building regulations now require that all new houses be fitted with mains powered smoke detectors. By monitoring environmental data, early warning signs of threats can be detected, appropriate alerts made and lives can be saved.\\\\
Many companies offer monitoring systems for break-ins on a subscription basis. The alerting model usually involves the detection of a breach in security, which triggers an alert to a remote operations centre, which then alerts the emergency services, neighbours or any other listed third parties. PhoneWatch offer by Eircom is an example of this type of service. \\\\
Nest Labs have created a number of embedded solutions for home automation and safety. For safety specifically, the Nest Protect system incorporates smoke, carbon monoxide, heat, and activity detection sensors. Surveillance cameras can be added also, to provide additional security. The system they have implemented is limited in terms of sensor configuration, not providing the user with any access to sensor managemnet. Their UI focuses on environmental events, such as spikes in carbon monoxide, but does not allow the checking of the actual sensor value experienced. My solution aims to display detailed sensor readings and aggregated values, which will give acute insight into environmental conditions across varying periods of time. 

\subsection{Achieving Safety and Security within the Home}
Choosing periphery sensors to improve safety and security involved identifying the main threats which can occur within a domestic environment. I settled on the following as a basis for what my system was to mitigate against.

\begin{itemize}
  \item Fire and Smoke
  \item Carbon Monoxide
  \item Gas leaks
  \item Intruders 
\end{itemize}

\noindent
Providing the user with appropriate feedback on current sensor levels is an essential aspect of ensuring safety. The methods of delivering this varying type of feedback depends on both the proximity of the user, and the severity of the particular sensor reading. Giving the user the ability to configure the way in which the system alerts them ensures that they consciously choose the most appropriate method of doing so. The possible methods of alerting that were considered for the project are:

\begin{itemize}
  \item Smart phone push notifications
  \item An on board buzzer
  \item Email	
  \item Direct Tweet via Twitter
  \item SMS 
\end{itemize}

\subsection{Embedded Computing}
\subsubsection{Raspberry Pi}
The Raspberry Pi is a single board microcomputer, roughly the size of a credit card. It has a 700MHz single core 32-bit RISC ARM Processor(ARM11), along with 512 MBs of SDRAM. There are 26 general purpose input and output pins present on the board. A Secure Digital(SD) card provides all storage, including the Raspbian operating system. Raspbian is a lightweight version of Debian Linux, which has been customised specifically by the Raspberry Pi Foundation. There is a full GPU on board, and a HDMI port for connection to a monitor. The Raspberry Pi model 1 B was used for the project. \\\\
The community behind the Raspberry Pi is very extensive, and having over 5 million units sold since its initial release, a lot of experimentation has been done with the board. The original purpose was to provide a cost effective educational computer, but the applications of the Pi have far exceeded this.\\\\
The Pi can be up and running within 20 minutes of first receiving it. The simplistic documentation and well maintained repositories present on the Raspbian OS mean that development with the board can begin rapidly. 
\subsubsection{Intel Galileo}
The Intel Galileo is a single board microcomputer, slightly larger than the size of a credit card. It has a 400MHz Quark SoC X1000 32-bit single core pentium-class x86 CISC processor, along with 256 MBs DRAM and 512KB on-chip SRAM. There is no GPU present on the board. The Galileo is Arduino-Certified, and can use a version of the Arduino IDE for development. For the Galileo\rq s operating system, a lightweight embedded Linux distribution called Yocto is used. \\\\
The community behind the Intel Galileo is considerably smaller than that of the Raspberry Pi. When dealing with problems with the Galileo board, it is much more difficult to find online solutions or tutorials. Intel maintain two repositories for the Yocto OS, one with preinstalled development software, and the other without. Getting setup with the Galileo takes some additional time as there are many options for connecting to it: direct ethernet, serial, or USB. 

\newpage
\subsection{Functional Specification}
An embedded sensor system and Android smart phone application which supplies the user with live environmental data and security services. \\\\
The following sensor modules will be included:

\begin{itemize}
  \item MQ-7 Carbon Monoxide Sensor
  \item MQ-2 Flammable Gas \& Smoke Sensor
  \item Infrared Motion Detection Sensor	
  \item Thermistor for Temperature levels
  \item Buzzer for immediate vicinity alerting
  \item Raspberry Pi HD Camera module for Image capture and live video streaming 
\end{itemize}

\noindent
The Android application will take advantage of the latest Android APIs, and follow modern UI and UX guidelines. 

\subsubsection{Functional Requirements}
The system should be configurable by the user, allowing the control of each individual sensor, data management, alerting services, and general system details. \\\\ The system should have the ability to alert the user remotely.  \\\\ The gathered sensor statistical data will be graphed for the user to monitor readings over extended periods of time. \\\\ Context sensitive feedback will be provided to the user on current sensor readings. \\\\ The system should include a mechanism for direct communication, allowing the system to operate in environments where network connectivity is limited. All original functionality should be available when directly communicating. \\\\ The system should provide a device authorisation process, where one single user can have full administrative control, and allow all others only limited access.  \\\\
The system should have a interface for connection with additional sensing devices. 

\subsubsection{Non-Functional Requirements}
The system should be operable irrespective of network connectivity. \\\\ The implementation should be extendable and allow for easy inclusion and integration of any desired sensor module. \\\\ Consideration should be give to optimisation, in order to reduce CPU load and maximise speed. \\\\ Interaction with sensor modules in particular will require close attention to ensure efficient and accurate readings are obtainable. \\\\ The system will be powered via the mains, but attention should be given to maximizing efficiency to allow the move to alternative power sources in the future, i.e. solar or wind. \\\\ Care should be taken when designing the data layer of the system, ensuring optimal memory management.

\newpage
\section{Design}
\subsection{Development Approach and Methodology}
In a development project of this scale and time frame, a hybrid development approach of Agile and Rapid Application Development(RAD) was determined to the most suitable. This hybrid model offered flexibility for the system to change and evolve during its design and implementation, while also providing working software early on. During the implementation phase of development the prototyping aspects of RAD were utilised for the feasibility testing of design decisions. \\\\
From the beginning of the project it was evident that a process heavy methodology to development would constrict the time frame of the system\rq s overall development. Applying an iterative and incremental agile approach reduced the time spent in planning, allowing a longer development phase. This is not to say that planning played a lesser role in the system’s life cycle, but that essential core functionality was defined and a rudimentary version of the system designed early in the project\rq s life cycle. Using this initial core design, implementation of the subsystems began, and in parallel with their development, any desired additional functionality or feature was incrementally designed and integrated.

\subsection{Architecture}

\subsubsection{Hardware}
The final hardware architecture of the system comprised of a Raspberry Pi, with four sensors attached; a thermistor for temperature readings, an MQ7 carbon monoxide sensor, an MQ2 flammable gas sensor, and a passive infrared motion detection sensor. Also connect to the Raspberry Pi was a high definition camera module, a wifi dongle and a buzzer for alerting the user. \\\\
The Raspberry Pi was chosen as I had some experience working with it at a high level.

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{"rasp_pi".JPG}
\caption{Raspberry Pi board}
\label{fig:hard_rasp_pi}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=8cm]{"temp".JPG}
\caption{Thermistor sensor module}
\label{fig:hard_temp}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=8cm, height=9cm]{"mq7".JPG}
\caption{MQ7 carbon monoxide sensor module}
\label{fig:hard_mq7}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=8cm, height=9cm]{"mq2".JPG}
\caption{MQ2 flammable gas sensor module}
\label{fig:hard_mq2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=6cm, height=6cm]{"infrared_motion".JPG}
\caption{Passive infrared motion detection sensor}
\label{fig:hard_motion}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=8cm, height=8cm]{"camera".JPG}
\caption{HD camera}
\label{fig:hard_camera}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=8cm, height=8cm]{"dongle".JPG}
\caption{Broadcom Wifi dongle}
\label{fig:hard_camera}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=8cm, height=8cm]{"buzzer".JPG}
\caption{Buzzer}
\label{fig:hard_camera}
\end{figure}

\subsubsection{Software}
The final software architecture was composed of three main components, with the addition of a peripheral sensing system, which was something introduced during the development phase.

\begin{itemize}
  \item The Sensor Management System physically running on the Raspberry Pi
  \item The server side RESTful API running on CS1
  \item The Android application
  \item Peripheral Sensing System running on an Intel Galileo 
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=16cm]{"Open Day General System Diagram".jpg}
\caption{High level system architecture diagram}
\label{overflow}
\end{figure}

\paragraph{Sensor Management System}
\noindent
\\\
This will form the core of the entire system, managing all sensor module interaction. Sensor value monitoring and alerting service triggering should take place natively on the system. \\\\ The system will allow direct connection via the Android application. To accomplish this, the system should maintain its own private wireless network, in the form of a non-internet facing access point(AP). A protocol for establishing connection and full-duplex communication from the system to the Android application will be designed, allowing sensor data transfer and system configuration. \\\\ 
Three local database tables will be required for operation:

\begin{itemize}
  \item Sensor values table
  \item System meta data, including name, location, and approximate GPS coordinates 
  \item System admin details for authentication and control
\end{itemize}

\paragraph{RESTful API}
\noindent
\\\
This will form the server side backend of the system, and provide the application programming interface(API) for both the Sensor Management System, and the Android application. Functionality includes persistent cloud storage and retrieval of sensor readings, camera assets management, and remote configuration of the Sensor Management System.

\paragraph{Android Application}
\noindent
\\\
This will form the user interface of the overall system. The application will provide sensor output levels, a gallery of camera stills and videos, graphed statistical data on previous sensor readings, and a configuration interface for the system.\\\\
Related safety feedback information should be delivered to the user via the app. A dataset of safety metrics linked to the sensor output readings will be developed offering the user real time advice in plain english.\\\\\
The app will utilise the server side RESTful API as its main communication intermediary to the system, but will also have the ability to connect directly, allowing it to read sensor data straight from the Sensor Management System, and update the system\rq s configuration. \\\\
Push notification functionality should also be include to provide the user with remote alerting.

\paragraph{Peripheral Sensing System}
\noindent
\\\
A scaled back version of the Sensor Management System, only operating at a rudimentary level. This will act mainly as a proof of concept, to demonstrate the core system\rq s ability to connect and interact with peripheral devices. 

\subsection{Design Decisions}
The initial software architecture was for a self contained system with each component running natively on the Raspberry Pi. While it is a very capable device, as more computational power was required for the operation of the system, the feasibility of running a server in parallel came into question. Using the Glances Python utility \footnote{http://pypi.python.org/pypi/Glances/}, I was able to actively monitor the CPU performance of the Raspberry Pi while the system was in operation, which constantly remained above 60\%, even in the early stages of development. In order to safeguard against congestion and drops in overall performance, an alternative solution was devised to reduce load on the Raspberry Pi. This lead to the adoption of a client-server architecture involving the system periodically sending data to CS1, where it could be stored, and delivered to smart phone applications, greatly reducing the computational load on the physical device. \\\\
A Representational State Transfer(REST) architecture was chosen to provide the server side backend functionality required to service both the Sensor Management System and the Android application. REST is a lightweight alternative to a Simple Object Access Protocol(SOAP) solution, which would utilise the Web Services Description Language(WSDL), an XML based interface definition language. The main advantages of REST are its extensibility, simplistic design and portability. \\\\
The user Interface for the system was initially in two parts, a web interface for graphing the collected sensor data, and the Android application, for current readings, control and alerting. As the project progressed, the choice was made to unify the UI, providing all functionality in the Android application.  \\\\
In order to maximise performance, every subsection of the system was multithreaded where possible. With this decision came the added complexity of appropriate thread management and synchronization. The Raspberry Pi has a single core, so no substantial benefits were apparent when developing the system, but in the eventuality of migrating to more powerful hardware, instant performance improvements will be experienced. \\\\
In order to maximise sensor performance, all interaction directly with sensor modules is implemented in C, with a C++ infrastructure to avail of basic object oriented principles such as inheritance and extensibility. This was chosen to reduce the CPU load when probing sensor modules. In order to utilize the C++ implementation, it was necessary to develop a Python wrapper, providing the ability to access sensor values at greater speeds than a standalone Python implementation. \\\\
A core feature of the overall system is providing the user with rapid alerting. With that in mind, it was decided that alerting should be handled natively in the Sensor Management System. The alternative was to perform safety checking server side, but this may lead to alert latency.
\subsection{Data Storage}
MySQL was chosen as the Relational Database Management System(RDBMS). While its use and interaction is facilitated in most modern programming languages, the real benefit comes from its aggregation functions. Having the ability to select maximum, minimum, and average values from the database in a concise SQL statement greatly reduces the amount of code required, and as rows can be indexed and prepared statements optimized, overall performance is booted also. \\\\
Using a NoSQL database was considered as the performance and scalability benefits can be substantial when compared with generic SQL databases. NoSQL databases required a substantial amount of code to be written for interaction and aggregation, something which comes as standard in all SQL storage systems. This deterred adoption. \\\\
The Raspberry Pi is running an instance of the MySQL RDBMS, while the RESTful server side system is maintaining a database of tables which is identical to those present in the natively running instance. This provides data redundancy, and in the eventuality of the server side system becoming unreachable no data will be lost.
\subsection{Data Modelling}
As memory is a constant constraint when dealing with an embedded system, consideration was put into optimising the structures of the tables within the RDBMS. Due to a lack of time when implementing the system, only one table was eventually used for sensor readings, however the original design contained three tables to minimise memory usage. A table for all current day sensor readings, another table for aggregated readings per hour of each day, and a final table for a summary of aggregated readings per day. The data was then to be aggregated automatically at a given time interval, and reduced into the subsequent table. This way, over time the data growth would be limited. \\\\
A table was created to store the system\rq s details, such as its name, location, and GPS co-ordinates. \\\\
For push notifications, it is necessary to maintain a table for all registered device identification numbers. These IDs are to be stored via the RESTful API and are used when sending out a push notification to a device. 
\subsection{Communication Design}
Developing a distributed architecture involved designing a message passing mechanism utilising Javascript Object Notation(JSON), a lightweight data-interchange format. It’s native support in most modern programming languages and easy to manipulate syntax facilitated fast integration in each subsystem. \\\\
XML was considered, but its use is more applicable to heavily structured documents.  Library support for object serialization to JSON greatly promoted rapid application development, providing the ability to easily communicate current sensor readings and system configurations across a network. \\\\ A standard structure was defined for the JSON messages being communicated. \\\\
\newpage
\noindent
The basic structure was as followed: 
\begin{lstlisting}[caption={JSON Message Structure},label={lst:json_message}]
{ 
  “service” : "Requested Service",
  “payload” : "Data to be transmitted"
}
\end{lstlisting}

\noindent
The service key indicating the service being requested, and the payload containing the data to be acted upon.

\subsection{User Interface}
The Android application is the only user Interface(UI) for the project. The platform provides a UI framework and a large amount of extensible UI view components, which can be combined with ease. The Android OS offers native animations and effects for improving user experience(UX), allowing the creation of visually responsive features with little effort. \\\\ The UI was designed with simplicity in mind. The clear and concise presentation of data to the user was the main priority. To achieve this, core aspects of functionality were designated individual screens within the application. \\\\ The UI is composed of 4 screens. The initial screen where the latest sensor data is presented. The camera screen, where captured images and videos are presented. The graphing section, were line charts display sensor value statistical information. And the final section is the control and configuration options, where the system can be reconfigured. \\\\ As the application has the build in functionality for communicating directly with the sensor management system, it was necessary to design the UI to respond accordingly to how the application is receiving its data.

\subsection{Alerting}
The method of remote alerting chosen was push notifications, via the Google Cloud Messaging(GCM) Service. \\\\ 
The GCM is a free service that enables developers to send downstream messages (from servers to GCM-enabled client apps), and upstream messages (from the GCM-enabled client apps to servers). This could be a lightweight message telling the client app that there is new data to be fetched from the server (for instance, a "new email" notification informing the app that it is out of sync with the back end), or it could be a message containing up to 4kb of payload data (so apps like instant messaging can consume the message directly). The GCM service handles all aspects of queueing of messages and delivery to and from the target client app.\footnote{Description taken from http://developer.android.com/google/gcm/gcm.html}

\newpage
\section{Implementation	}

\subsection{Tools and Techniques}
Each component of the system was implemented using a different programming language, with the exception of the Principal Sensing System. As a result, each was developed using a different set of tools, techniques and libraries. The reliance on Integrated Development Environments(IDE) to increase productivity and mitigate against syntactical errors was paramount to the rapid development of the project. 

\paragraph{Sensor Management System}\

\noindent
Implemented in Python, a very flexible and easy to use dynamically typed language. Its succinct nature and dynamic typing aid rapid application development. The community support behind the language also greatly encouraged its adoption for this section of the system. \\\\ To implement, I used the PyCharm IDE. This provided real time code validation, automated code generation and syntactical checking.

\paragraph{RESTful API}\

\noindent
Implemented in the server side language PHP. PHP offers a lot of server side functionality as standard, and required no third-party libraries to facilitate the features that were required. This will prove beneficial in the situation of migrating servers. \\\\ Deployed on the university\rq s Apache web server, CS1. Utilising this pre-existing infrastructure resulted in less overhead when initially starting the project, allowing the development phase to begin earlier. 

\paragraph{Android Application}\

\noindent
Native Android applications are implemented in Java, and use XML for specifying their user interfaces. It is possible to design applications in HTML and CSS, embedding them in the application within a WebView, which handles rendering, but this greatly hinders performance, and limits the use of the native device APIs, such as location services and animations. \\\\ Android Studio, the officially supported IDE for Android development, was used to develop the application. It is based upon the Intellij platform of IDEs, and provides a graphical interface for developing Android user interfaces.  

\paragraph{Peripheral Sensing Node}\

\noindent
Python was also used when developing this additional entity of the system, allowing a lot of code reuse. This made interoperability more straightforward when integrating the two sensing systems together.

\newpage
\subsection{Sensor Management System}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{"Sensor Management System Diagram".jpg}
\caption{Sensor management system high level diagram}
\label{fig:sms_high_level_arch}
\end{figure}

\subsubsection{Sensors and Peripheries}
To control sensors connected to the Raspberry Pi, the open source WiringPi C/C++ general purpose input/output(GPIO) library was employed. It provides basic interaction mechanisms for both analog and digital sensors. The community support for this library is substantial, and has become the de facto standard library for embedded Raspberry Pi projects. A wiring diagram can be seen in Appenix A, Section~\ref{sec:appendix_a}. \\\\
A limitation of the Raspberry Pi is that is does not provide any analog GPIO pins. To overcome this, an additional analog to digital converter(ADC) was added to the system’s circuitry. The MCP3008 ADC, an 8 channel 10-bit analog input,  was chosen due to its support in the WiringPi GPIO code library. This facilitated easy access to any analog sensor that needed to be included. \\\\

\begin{figure}[H]
\centering
\includegraphics[width=6cm, height=10cm]{"mcp3008".JPG}
\caption{MCP3008 analog to digital converter}
\label{fig:hard_adc}
\end{figure}

Each individual sensor required a slightly different code implementation. \\\\
The MQ7 carbon monoxide(CO) analog sensor needs a heating cycle of 5v for 60 seconds, and 1.3v for 90 seconds continuously for 48 hours, until a true value of 0 is output. This is due to the sensor being sensitive to other chemical elements, in particular Hydrogen. The heating cycle is designed to burn off excess molecules touching the senor\rq s filament, resulting in more accurate readings. \\\\ While in the heating cycle, the sensor is capable of detecting variances in CO levels. In order to provide the user with accurate data, an algorithm was defined to monitor differences in CO levels. By recording previous values, tracking current value increases or decreases, and presenting the user with the difference in values, allowed accurate CO readings from the moment the system is started. \\\\
The MQ2 flammable gas analog sensor can detect liquefied petroleum gas, i-butane, methane, alcohol, Hydrogen, and smoke. It also required a heating cycle identical to the MQ7. \\\\
The passive infrared motion detection digital sensor measures infrared (IR) light radiating from objects in its field of view. It can detect humanoids/pets from up to 20 feet away. \\\\
A passive analog thermistor was chosen to provide temperature readings. \\\\
A passive buzzer was included in the system’s circuitry also, to provided local proximity alerting. \\\\
To capture visual data, the high definition Raspberry Pi camera module was included. As this module is produced by the developers of the Raspberry Pi board, very little code implementation is required to perform interaction, and two comprehensive libraries, Raspivid and Raspistill,  are natively available to handle video and image capture respectively.

\subsubsection{Sensor Management}
Within the system, each sensor was defined within its own individual class. Abstracting individual sensors like this allows for granular configuration, and the delegation of alerting responsibility to the individual module. Each sensor has an alerting threshold, which when met will perform the necessary alerting functionality. The rate at which the sensor is probed is also configurable. Each sensor has its own priority that is used for multithreading, and also in the eventuality of the system becoming alternatively powered, it would allow for graceful degradation as power levels diminish. \\\\
The Sensor Manager class see in Figure~\ref{fig:sms_high_level_arch} facilitates high level sensor orchestration. Its incharge of data collection, and thread management. A thread is created for each sensor, which is scheduled to run in the interval denoted by its probe rate. It is not necessary for all sensors to be updated constantly, by implementing the probing in this way, safety critical sensors, such as the MQ2 Flammable Gas sensor, can be configured to update its value every second, while a non-safety critical sensor, such as the thermistor, can be probed at longer intervals. In the eventuality of changing the power source of the system, it would also facilitate the marshaling of power exhaustive sensors, allowing dynamic scheduling as resources diminish. 

\subsubsection{Multithreading}
The Raspberry Pi’s processor, the ARM1176JZF-S, has a single core. While it is not a true multithreaded environment, the decision to multithread the system was taken to ensure a high level of portability. Over the course of this project a new Raspberry Pi model 2 was released. The new model contains 4 cores, and an increase amount of RAM, of 1GB. The multithreading already featuring in the system would allow for swift migration to this new Raspberry Pi model 2, and instant performance benefits.

\subsubsection{System Configuration}
\label{sssec:sms_sys_config}
In order to make the system fully configurable, an abstract base class, called Configurable, was implemented, which all manager classes in Figure~\ref{fig:sms_high_level_arch} inherit from. This class provides the layer of abstraction needed to dynamically update the state of each object. The system does not required halting when reconfiguring. \\\\
The Javascript Object Notation(JSON) was utilised as the means for specifying the required state configuration of individual classes. The Configuration Manager, in Figure~\ref{fig:sms_high_level_arch}, was delegated the responsibility for administering the updating of the system\lq s configuration. Listing~\ref{lst:sms_json_config} shows the default JSON configuration structure. It contains an object for each manager class present in the system, and an array of sensor objects with individual state values for each. \\\\
The System is configurable form two sources, via the RESTful API, or direct from the Android application. To achieve remote configuration, the system periodically polls the RESTful API for an updated configuration file. If present, it requests the raw JSON string, parses it, and then reconfigures the system accordingly. The time interval at which the system polls is also configurable. Via direct communication, the user can push a new configuration at their own discretion. 
\newpage
\begin{lstlisting}[caption={JSON configuration structure},label={lst:sms_json_config}]
{
  alert_manager: {
    "buzzer_on": false,
    "camera_on": true,
    "lockdown_on": false,
    "push_on": false,
    "video_mode": false
  },
  api_manager: {
    "camera_image_upload_rate": 60,
    "sensor_value_upload_rate": 30,
    "sys_config_request_rate": 60
  },
  sensor_manager: {
    "collection_priority": 1,
    "collection_rate": 15
  },
  system_details_manager: {
    "gps_lat": "Not set",
    "gps_lng": "Not set",
    "location": "Sitting Room",
    "name": "Kevin's Safety System"
  },
  wifi_direct_manager: {
    "sensor_value_send_rate": 10
  },
  sensors: [
    {
      "name": "carbon_monoxide",
      "alert_threshold": 50,
      "is_active": true,
      "priority": 1,
      "probe_rate": 10
    },
    {
      "name": "flammable_gas",
      "alert_threshold": 50,
      "is_active": true,
      "priority": 1,
      "probe_rate": 10
    },
    {
      "name": "temperature",
      "alert_threshold": 50,
      "is_active": true,
      "priority": 1,
      "probe_rate": 10
    },
    {
      "name": "motion",
      "alert_threshold": 1,
      "is_active": true,
      "priority": 1,
      "probe_rate": 10
    }]  
}
\end{lstlisting}

\subsubsection{Alerting}
The system alerts in two ways. Proximity altering in the form of a physical buzzer present on the circuitry, and direct mobile device push notification alerting via the Google Cloud Messaging(GCM) Service. The system can be configured to be in a lockdown state, where in the event of the infrared motion detector detecting activity, the on board camera is activated. \\\\
Each sensor maintains its own alerting threshold, and when reached it performs its defined behaviour. For example, when the carbon monoxide sensor\lq s threshold is reached, a push notification is sent, and the physical buzzer attached to the system’s circuitry is sounded. \\\\
To send a push notification, a registration process must first take place between the Android application and the GCM service. This process is described in the Android application implementation push notication section~\ref{sssec:android_push_notifications}. Resulting from this registration is a unique device identification number, which must be persistently stored. In this implementation, the registration ids were stored by the RESTful API, and retrieved prior to sending each push notification. \\\\
The registration id is sent along with a JSON formatted payload via a HTTP request to the GCM service, which handles delivering the payload to the respective device. An example push notification payloa can be seen below in Listing~\ref{lst:sms_pn}.
\begin{center}
\begin{lstlisting}[caption={JSON push notification payload example},label={lst:sms_pn}]
{sensor : "thermistor", value : 100, location: "Sitting Room"}
\end{lstlisting}
\end{center}
The key "sensor" identifying the individual sensor module, the key "value" denoting the current sensor reading, and the "location" key is the user specified location of the system which has invoked the sending of the notification. \\\\
In the implementation, the Alert Manager, seen in Figure~\ref{fig:sms_high_level_arch}, is delegated all alerting responsibilities. Other than push notification requests, it also handles sounding of the buzzer, and camera operation. 

\subsubsection{Video and Image Capture}
The Raspberry Pi has an on board Mobile Industry Processor Interface(MIPI) compliant Camera Serial Interface. The HD camera module, also developed by the Raspberry Pi Foundation, is attached directly to this CSI port. The module has a five megapixel fixed-focus camera that supports 1080p30, 720p60 and VGA90 video modes, as well as still image capture. It attaches via a 15 cm ribbon cable. To interact with the camera, two command line tools are present natively in the Raspbian OS, Raspstill and Raspvid. These allow still image and video capture respectively. \\\\
The system performs the following tasks with the camera module.
\begin{itemize}
  \item Still image and video capture, uploaded to the backend server, or delivered 	directly to the Android application via a Secure File Transfer Protocol(SFTP) server running on the Raspberry Pi
  \item Local and Remote video streaming over HTTP
\end{itemize}
To perform video streaming, the open-source VLC Media Player was chosen to provide the necessary functionality. Inbuilt within VLC is a streaming media server, which can be invoked programmatically, and allows for the specification of a wide range of media encoding, streaming, and networking options.\\\\
When called, the system simply uses the Raspvid command line utility to start video capture, and pipes the output to the VLC media streamer, which then constructs the necessary infrastructure for the network stream. \\\\
When directly communicating, the Raspberry Pi has a Secure File Transfer Protocol(SFTP) Server running as a daemon which allows protected access to the captured images and videos. This is later utilized programmatically by the Android application.

\subsubsection{API Communication}
\label{sssec:sms_api_comm}
The API Manager class, seen in Figure~\ref{fig:sms_high_level_arch}, orchestrates all network communication with the RESTful API.
The API Manager performs the following tasks:
\begin{itemize}
  \item Uploading of current sensor values
  \item Requesting of updated system configurations
  \item Uploading of images and videos
  \item Retrieving of device registration ids for push notification alerting
\end{itemize}
Each of theses operations is scheduled in its own thread, making their timing individually configurable.  All communication with the RESTful API is carried out via the HTTP POST method.\\\\
To identify the service requested when communication with the RESTful API an additional HTTP header called "service", is added to the request. This is parsed server side and the corresponding functionality executed. There are efficiency benefits with this approach in the cases of checking for updated configuration or requesting push notification device ids, as no data is sent in the request body, minimising the overall request size. \\\\
An example of the request body for sensor values to be uploaded to the RESTful API can be seen in Listing~\ref{lst:json_sensor_values_example} below. As the service being requested is contained in the request header, the content body is minimal in size and complexity.
\begin{center}
\begin{lstlisting}[caption={Sensor Values Request Body Example},label={lst:json_sensor_values_example}]
{'motion': 1, 'flammable_gas': 0, 'carbon_monoxide': 80, 'temperature': 65}
\end{lstlisting}
\end{center}
With every HTTP request, there is a subsequent HTTP response. To minimise the overall number of HTTP requests needed for operation, additional information is passed back to the Sensor Management System in the response payload. Standard fields in the payload include a status code for reactive error handling, and a timestamp for monitoring latency. Additionally included is a flag for indicating which camera action is being requested. This allows for the requesting of remote video stream, or still image capture without the need for additional API calls. \\\\
Incorporated in the API Manager class are a number of fault tolerance mechanisms to protect against unexpected network loss. By employing Python\rq s Try/Except functionality, this class can gracefully fail when network connectivity is unavailable, and automatically continue performing its tasks once connectivity is re-established.

\subsubsection{Direct Communication}
\label{sssec:sms_direct_comm}
The system required the ability to directly communicate to the Android application, allowing operation in situations where there is no available connection to the internet.\\\\
Originally Wifi Direct was chosen as the means for direct communication. The Wi-Fi Direct certification program is developed and administered by the Wi-Fi Alliance.
Wifi Direct allows for communication without an access point, and can cater for multiple peer connectivity. It works by creating a software access point(Soft AP) within the device that supports Direct, which peers can connect to and exchange data.  This Soft AP provides a Wifi Protected Setup(WPS) connection. The device creating the Sort AP is know as the group owner. As long as one device supports Wifi Direct, legacy devices can also connect and communicate directly. The resulting user experience is similar to that of a Bluetooth connection, but at normal Wifi speeds.\\\\
The Broadcom Wifi Adaptor designed to integrate seamlessly with the Raspberry Pi was chosen to allow the inclusion of Wifi Direct in the system. However, due to limitations of the Adaptor\rq s firmware not supporting Wifi Direct at the time of development, an alternative solution was sought. \\\\
To accomplish this feature, an access point(AP) administered by the Raspberry Pi was implemented. This also required the Raspberry Pi to run a Dynamic Host Configuration Protocol(DHCP) server, to automate connected device IP allocation. The AP was configured to be completely local, and not forward any traffic to the wider internet. \\\\
To connect to the Sensor Management System, firstly the device must be connected to the Raspberry Pi\rq s AP. Next the device must initiate a connection handshake by sending a connection message to identify itself and specify the type of device it is. The identification is handled differently depending on the type of device. For an Android device, it uses a unique 64-bit hex string device id which is obtained directly from the Android OS. For peripheral sensing nodes, a 48 bit integer representing the device\rq s MAC address is used. \\\\
The Sensor Management System maintains a multicast channel, on a pre-specified IP address and port number. It listens on this IP address for connection messages, and drops all but those which conform to the defined format, seen in Listing~\ref{lst:json_device_connect} below. \\\\
The message in Listing~\ref{lst:json_device_connect} is sent from an Android device to the specified multicast channel IP address, where the Sensor Managment System is listening. A connection verification message is then sent back to the Android device, and if the connection was successful, data passing begins. Alternatively, if unsuccessful, pairing must be reinitiated by the Android device. In the case of the Peripheral Sensing System failing to connect, it retrys every 10 seconds.
\begin{lstlisting}[caption={JSON Connection Message Object},label={lst:json_device_connect}]
{  
   service:"connect",
   payload:{  
      session:{  
         device_id:"e1cadbafc6804e3f",
         ip_address:"192.168.42.2",
         time_stamp:"2015-03-09 20:23:26",
         type:"android"
      }
   }
}
\end{lstlisting}
Once the connected, all further interaction is handled via direct TCP socket communication.\\\\
An additinal benefit of implementing device connection in this way is that multiple devices can join a multicast channel, forming a group. This facilitates the communication of messages to all connected devices easily. As new devices connect, all nodes on the network listening on this multicast socket can react accordingly. In the case of alerting, if a sensing device experiences conditions that warrant an alert to be issued, a message can be pushed to this multicast channel, and all devices listening can sound their alarms. \\\\
The Direct Communication Manager class encapsulates all the above system functionality. It periodically pushes data to the connected devices, and acts as an arbitrator for all incoming messages.\\\\
The multicast IP range of 224.0.0.0 to 239.255.255.255 is specified in RFC 5771, an Internet Engineering Task Force (IETF) Best Current Practice document (BCP51)
\footnote{http://tools.ietf.org/html/rfc5771}. The IP address 224.1.1.1 was used in the implemetation for the multicast channel. \\\\
The obvious shortcoming of this implementation is that the device must be connected to the system\rq s AP, disconnecting it from the wider internet. In terms of user experience(UX), a better solution would be to use Bluetooth Low Energy for the application to system communication. 

\newpage
\subsection{Peripheral Sensing System}
\subsubsection{General Operation}
A scaled down version of the Sensor Management System was designed and implemented to act as an additional Peripheral Sensing System within the home. Due to time limitations, the Peripheral Sensing System implementation is focused on gathering sensor data, and relaying it to the Sensor Management System. There is not persistent storage of sensor readings, and the system is static in terms of user configuration. \\\\
Two threads exist in the Peripheral Sensing System, both are used for communication with the Sensor Management System. One thread is purposed for gathering and sending sensor data, the other thread is for receiving data. 

\subsubsection{Hardware}
For this project, the Intel Galileo generation 1 was used as the hardware for the peripheral node. The Galileo was chosen to highlight the Sensor Management Systems ability to manage a heterogeneous network. The Grove Starter Kit Plus - Intel IoT Edition provides the base shield and sensors, which have a modular plug-and-play design. A wiring diagram can be seen in Appenix A, Section~\ref{sec:appendix_a}.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, height=10cm]{"galileo_board".JPG}
\caption{Intel Galileo gen 1}
\label{fig:hard_galileo}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=6cm, height=8cm]{"grove_kit".JPG}
\caption{Grove IoT sensor kit}
\label{fig:hard_grove_kit}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=8cm, height=6cm]{"grove_sheild".JPG}
\caption{Grove base shield}
\label{fig:hard_grove_sheild}
\end{figure}

\noindent
Attached to the Galileo, via the Grove base shield, are an LED, a temperature sensor, a light sensor, and a touch sensor.\\\\
The touch sensor was included to demonstrate remote alerting, as when it receives input, it sends a message to the core Sensor Management System, which sounds a buzzer. Similarly, the LED was included to demonstrate message passing in the opposite direction, from the core system to the Galileo. 

\begin{figure}[H]
\centering
\includegraphics[width=6cm, height=6cm]{"grove_light".JPG}
\caption{Grove light sensor module}
\label{fig:hard_grove_light}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=6cm, height=6cm]{"grove_temp".JPG}
\caption{Grove temperature sensor module}
\label{fig:hard_grove_light}
\end{figure}

\noindent
In order to avail of high level software, such as Python and Git, it was necessary to boot the Galileo from an SD card with the Yocto system image.
\newpage
\subsubsection{Communication with Sensor Management System}
The core Sensor Management System provides the communicational infrastructure to allow any device capable of connecting to the system\rq s AP to become a peripheral sensing node. The same connection mechanism is used in Section~\ref{sssec:sms_direct_comm}, Sensor Managemnt System Direct Communication. The only alteration is that the device looking to connect is required to specify its type as peripheral. \\\\
The Peripheral Sensing System is configured to periodically gather all sensor data and send it to the Sensor Management System. Data is sent every 10 seconds, starting once the device is connected. An example of an outbound peripheral message can be seen in Listing~\ref{lst:json_peripheral_sensor_message}.

\begin{lstlisting}[caption={JSON peripheral sensor readings message object},label={lst:json_peripheral_sensor_message}]
{  
   service:"peripheral_sensor_values",
   payload:{  
      peripheral_sensor_values:{  
      	 device_id:"167469062838880",
         time_stamp:"2015-03-07 22:14:15",
         touch:false,
         light:14,
         temperature:15,
      }
}
\end{lstlisting}

\newpage

\subsection{RESTful Application Programming Interface}
\subsubsection{General Operation}
To provide a remote communication interface for the Sensor Management System and the Android application, a representational state transfer(REST) architecture was implemented as the server side infrastructure for the project. The API runs on CS1, the department\rq s web server. For storage, a MySQL database is used.  \\\\
Its responsibilities include:
\begin{itemize}
  \item Sensor data storage and retrieval
  \item Remote configuration of the Sensor Management System
  \item Remote camera operation
  \item Image and video storage
  \item Push notification registration ID storage and retrieval
  \item Aggregation of sensor data for graph presentation
\end{itemize}
REST was chosen over SOAP as it facilitates rapid application development. Each component of the project architecture is implemented in a different programming language. The interoperability of REST removes the complexity of platform specific API communication. All components can utilise a single RESTful interface over HTTP using  JSON as the notation for messaging. This has the added benefit of making it instantly compatible with the current system’s messaging format.

\subsubsection{Request Management}
Following the standard REST architectural style all communication is handled via HTTP requests. The content body of each message takes the form of a JSON encoded object. As described in section~\ref{sssec:sms_api_comm}, Sensor Management System API Communication, an addition header value, called "service", is attached to each API request, specifying the desired service. The RESTful API simply reads this value, and manages the request payload accordingly. \\\\
In order to provide remote video streaming, the Sensor Management System\rq s public WAN IP address must be tracked at all times for use by the Android application when accessing the remote video stream. For every request sent from the Sensor Management System, the API records the public IP address persistently.

\subsubsection{Response Management}
\label{sssec:api_response_mgmt}
To reduce the number of API calls needed for operation, attached to the response of each request are a number of additional fields. \\\\
With all responses from the server to both the Sensor Management System, and the Android application, a status code for the completed service is included, to allow for reactive error handling. In keeping with the W3 RFC2616~\footnote{http://www.w3.org/Protocols/rfc2616/rfc2616.html} HTTP/1.1 status code specification, the following status codes were used. \\\\
\begin{table}[H]
\def\arraystretch{1.5}% 
\begin{center}
 \begin{tabular}{|| c | c ||} 
 \hline
 \textbf{Status} & \textbf{Status Code}  \\ [0.5ex] 
 \hline\hline
 Successful & 200 \\ 
 \hline
 Bad Request & 400 \\
 \hline
 Not Found & 404 \\
 \hline
 Server Error & 500 \\ [1ex] 
 \hline
 
\end{tabular}
\end{center}
\caption{API Status and Corresponding Codes}
\end{table}
\noindent
This method facilitates case based reactive error handling, and allows for easier debugging as the problem is automatically narrowed down to one of three possibilities. A timestamp is also included for general debugging purposes. Depending on where the request originated, further additional fields may be included. \\\\
When the request originated from the Sensor Management System, a field called "camera\_ operation" is added, with a numeric value attached, which represents the required camera operation. An example can be seen below in Listing~\ref{lst:json_api_response_sms}.
\begin{lstlisting}[caption={JSON API response to Sensor Management System},label={lst:json_api_response_sms}]
{
	camera_operation: 0,
	status_code:      200, 
	time_stamp:       "2015-03-07 22:14:15"
}
\end{lstlisting}
When the request originated from the Android application, the Sensor Management System\rq s public IP address is included in the response payload, which is needed went trying to access the remote video stream from within the application. An example can be seen below in Listing~\ref{lst:json_api_response_android}.

\begin{lstlisting}[caption={JSON API response to Android application},label={lst:json_api_response_android}]
{
	status_code:  200,
	pi_public_ip: "89.101.115.84"
}
\end{lstlisting}

\subsubsection{Video Streaming and Image Capture}
\label{sssec:api_video_and_image}
The API maintains a camera flag, stored persistently, which signifies the currently desired camera function to be executed, denoted by a numeric value. When the Android application makes a request for a remote stream, or image capture, the API updates this flag accordingly. \\\\
As described in section~\ref{sssec:api_response_mgmt} above, when the Sensor Management System makes a request to the API, contained in the response is the "camera\_ operation" field, populated by the value of the camera flag. \\\\
In this way, camera functionality can be invoked by the user, without the need for additional HTTP requests. There is a problem with this implementation however. The invoking of the camera function is constrained by the frequency of communication from the Sensor Management System to the RESTful API. In situations when communication is taking place in large time intervals, the same latency is experienced by the user when requesting a video stream. \\\\


\newpage

\subsubsection{Data Storage}
The API maintains 3 MySQL database tables, which take a simpler form than the original specification. The choice to simplify the schema was taken due to time constraints. The original design separating the sensor values table would limit the memory storage required, but also increase the underlying functionality needed to manage the additional tables. The final implementation accomplishes the same functionality, but at the loss of storage optimisation. \
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{"API SQL Schema".jpg}
\caption{Entity Relationship Diagram for RESTful API Database Schema}
\label{fig:api_schema}
\end{figure}

\subsubsection{Data Aggregation}
To optimise data aggregation for graphical presentation the original design specified three database tables for sensor data storage. One table for the current day sensor values, one table for current day values aggregated by hour, and a final summary table for aggregated values for days previous. The aggregated values include maximums, minimums and averages. \\\\
Partitioning the data in this way would reduce the overall storage capacity required. However, actively performing this aggregation on the database at regular time intervals would have been necessary.\\\\
Due to time constraints, to achieve the needed functionality, a single table was implemented, as seen in the Figure~\ref{fig:api_schema}. Aggregation is then performed on demand. This increases server load, and is not an optimal solution. 

\subsubsection{Push Notifications}
When registration with the Google Cloud Messaging Service is complete, the resulting device registration identification number given back must be persistently stored for later use. As can be seen in the entity relational Figure~\ref{fig:api_schema} above, the Push Notification Details table is dedicated to storing these registration IDs. When an alert threshold is reached by the Sensor Management System, an API call is made for theses IDs, which are then used to target the push notification to individual devices. 

\newpage
\subsection{Android Application}

\subsubsection{Application Structure}


\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, height=10cm]{"Android Application Structure".png}
\caption{Android application structure}
\label{fig:android_app_struct}
\end{figure}

There are three basic components of an Android application: activities, fragments and views. These form the basis for the Android view hierarchy. \\\\
The notion of an activity is a single, focused thing that the user can do. Activities create the window in which other components can be situated. They maintain a lifecycle, allowing the invocation of functionality depending on the current lifecycle stage. Figure~\ref{fig:android_app_struct} above shows the basic application structure, with the Main Activity at the application\rq s core \\\\
A fragment is a self contained module which encapsulates a variable number of view components. It can only exist within an activity. It represents a behavior or a portion of a user interface. It too maintains a lifecycle, which is more extensive than that of an activity. Figure~\ref{fig:android_app_struct} displays the four fragments embedded within the Main Activity, these are described in Section~\ref{sssec:android_ui_development} below.\\\\
Views are the building blocks for a UI. Views can be static, like a TextView, or interactive, like a Button. \\\\
The choice was made to only uses a single activity within the application, and delegate functionality to individual fragments, which are subsequently embedded within this activity. In this way a clear separation of functionality can be maintained, and cohesion can be kept high. The benefit of this structure, utilising an activity as the parent container, is that it facilitates more efficient application lifecycle and resource management, with single points of entry and exit. For example, in the eventuality of the application being closed, any active tasks such as API calls can be halted in a single location. \\\\
Also present in the application is a Wafeful Broadcast Receiver, seen in Figure~\ref{fig:android_app_struct} above, this is used for delivering and displaying push noifications. See Section~\ref{sssec:android_push_notifications} for a more indepth description.

\subsubsection{UI Development}
\label{sssec:android_ui_development}
Implementation of the Android application began with development of a general user interface structure.

\begin{figure}[H]
\centering
\includegraphics[width=8cm, height=10cm]{"opening_screen_shot".png}
\caption{Sensor data screen within the application}
\label{fig:android_opening_screen}
\end{figure}

\noindent
The UI follows a standard tabular design, which provides the user with an easy means of navigation. This can be seen in Figure~\ref{fig:android_navigation} below. The benefits of this navigational pattern is the flexibility it provides for introducing new fragments, or alternatively removing them.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{"nav_tabs".png}
\caption{Navigation bar within the application}
\label{fig:android_navigation}
\end{figure}

\noindent
Four fragments exist within the application, corresponding to the tabs in Figure~\ref{fig:android_navigation}. They serve the following individual purposes:
\begin{enumerate}
  \item Displaying of Sensor Readings, located under the Sensor tab
  \item Camera Operation, located under the Image tab
  \item Data graphing, located under the Stats tab
  \item System configuration, located under the Control tab
\end{enumerate}	

\subsubsection{Data Modelling and Management}
In order to maximise performance and reduce code within the application, no persistent database storage is used. Instead, when possible computation is delegated to either the server side API, or the Sensor Management System. This is to ensure that the application runs seamlessly, and is only required to perform small computational tasks. This allows for better management of limited resources to be designated to the application\rq s user interface components, ensuring their fluid operation. \\\\
Data is modelled within the application using JSON, maintaining the same structure as used in the other subsystems of the project. A key component to achieving swift parsing and serialization of JSON objects is a library called Gson. Gson, also known as Google Gson, is an open source Java library to serialize and deserialize Java objects to, and from, JSON. \\\\
To facilitate the easy inflation of Java objects, first a standard java object must be defined, with the appropriate attributes, as seen in Listing~\ref{lst:java_sensor_obj} below. The names of each attribute must match that of the JSON object being deserialized. 

\begin{lstlisting}[caption={Sensor object to be serialized},label={lst:java_sensor_obj}]
public class Sensor {
    protected String  name;
    protected boolean is_active;
    protected int     priority;
    protected int     alert_threshold;
    protected int     probe_rate;
}
\end{lstlisting}	

\noindent
To serialize, you create a new GsonBuilder object, and pass the object to be serialized to the "toJson" method, as seen in Listing~\ref{lst:java_sensor_string}. This will return a JSON formatted string corresponding to the attributes present in the object, displayed in Listing~\ref{lst:java_sensor_as_string}.

\begin{lstlisting}[caption={Serialize object to string},label={lst:java_sensor_string}]
String sensorJsonString = GsonBuilder().create().toJson(sensor);
\end{lstlisting}

\newpage
\begin{lstlisting}[caption={Sensor string resulting from serialization},label={lst:java_sensor_as_string}]
{  
   name:"temperature",
   alert_threshold:50,
   is_active:true,
   priority:1,
   probe_rate:10
}
\end{lstlisting}

\noindent
To deserialise the string, a new Gson object is created, and the "fromJson" method is invoked, passing in the JSON string and the Java class implementation to be populated. This returns a pure Java Sensor object, shown in Listing~\ref{lst:java_sensor_deserialize}.

\begin{lstlisting}[caption={Deserialize string to sensor object},label={lst:java_sensor_deserialize}]
Sensor sensor = new Gson().fromJson(sensorJsonString, Sensor.class);
\end{lstlisting}	

\subsubsection{Data Presentation}
Sensor value data is the first thing the user is presented with when opening the application. A GridView was used to achieve an extensible layout, with each sensor dedicated its own tile within the grid. Figure~\ref{fig:android_sensor_tile} shows a tile corresponding to the carbon monoxide sensor.  The sensor name is located at the bottom of the tile. The maximum and minimum values for the current day are placed at the right hand top corner. Directly in the center is the latest value, and just below is the measurement, in this case parts per million.
\begin{figure}[H]
\centering
\includegraphics[width=8cm]{"sensor_output".png}
\caption{Sensor Tile}
\label{fig:android_sensor_tile}
\end{figure}

\noindent
When a user defined sensor alerting threshold is reached, an additional icon appears on the tile corresponding to the alerting sensor. This can be seen in Figure~\ref{fig:android_sensor_tile_alerting} below. Note that this tile is for the infrared motion detector, and is binary valued, 1 denoting motion being detected. The value in the right top corner is the percentage of motion detected for the current day. 
\begin{figure}[H]
\centering
\includegraphics[width=8cm]{"sensor_output_alert".png}
\caption{An Alerting Sensor Tile }
\label{fig:android_sensor_tile_alerting}
\end{figure}

\noindent
Located above the sensor tiles is the name of the physical system the data is being displayed from. For the Sensor Management System this name is set by the user. Alternatively, when data is being displayed from a peripheral sensing node, it simply states the number of the node.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{"system_name".png}
\caption{Input System Label}
\label{fig:android_sensor_input_system}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{"peripheral_name".png}
\caption{Input System Label for Peripheral Device}
\label{fig:android_sensor_input_system_peripheral}
\end{figure}

\noindent
Underneath the sensor tiles in the bottom left corner is a text view which displays the date and time of the sensor readings, this can be seen in Figure~\ref{fig:android_sensor_timestamp}. In the right corner is the button which toggles between the physical sensing systems.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{"last_updated".png}
\caption{Last Updated Timestamp and System Toggle Button}
\label{fig:android_sensor_timestamp}
\end{figure}

\noindent
Figure~\ref{fig:android_peripheral_sensing_values} below shows the result of toggling the sensing system, where the readings are being displayed for the Peripheral Sensing Node, which was running on the Intel Galileo.
\begin{figure}[H]
\centering
\includegraphics[width=10cm, height=14cm]{"peripheral_screen".png}
\caption{Peripheral Sensing Node Sensor Values}
\label{fig:android_peripheral_sensing_values}
\end{figure}

\noindent
Each sensor tile has an on touch listener registered, so when a user touches a tile a dialog box appears. Context sensitive feedback corresponding to the current sensor value is presented to the user, and some information on the sensor itself. An example of which can be seen in Figure~\ref{fig:android_sensor_context_help} below.
\begin{figure}[H]
\centering
\includegraphics[width=10cm, height=14cm]{"context_help".png}
\caption{Context sensitive feedback for carbon monoxide reading of 100ppm}
\label{fig:android_sensor_context_help}
\end{figure}

\subsubsection{API Communication}
All network activity in the application is handled by a single HTTP library called Volley, which is developed by Google. It simplifies and optimises request management. It provides automatic scheduling, multiple concurrent connections, caching for both text and image data, and easy cancellation of requests. Volley utilises a priority queue as its underlying data structure for request execution. Optimisation is handled through the use of background asynchronous tasks, ensuring the main UI thread is not blocked which can result in latency that is apparent to the user. Volley offers extensible objects for creating JSON HTTP requests, a key feature that was required for interacting with the server side RESTful API.	\\\\
When developing the infrastructure for API communication, a singleton pattern was applied. This ensured that all network connectivity is coordinated by a single entity. Multiple benefits result from the use of this design pattern: classes which utilised API requests are kept simple as it is a noninvasive means of providing functionality, all currently executing requests can be cancelled simultaneously, which is useful when the application is halted by the user, and debugging is quarantined to a single location. Listing~\ref{lst:java_api_singlton} demonstrates the invocation of a request for the latest sensor values. 

\begin{lstlisting}[caption={Singleton API object method invocation},label={lst:java_api_singlton}]
API.getInstance(getActivity()).requestSensorValues(sccssListener, errListener);
\end{lstlisting}

\noindent
An example of the API call for sensor values is displayed in Listing~\ref{lst:java_api_call} below.
As mentioned in previous sections, in order to identify what service is being requested, an additional value is set in the header of the HTTP request. Volley allows a Map object to be added to the request specifying the header fields. The request itself is generic, using a placeholder object called APIResponse, which is populated when the response for the RESTful API is recieved. The APIResponse object can be seen in Listing~\ref{lst:java_api_response_obj}. The request object possesses two event listeners, one for handling errors, and the other for successful responses. The APIResponse object is delivered to one of these listeners when the request is complete. 

\begin{lstlisting}[caption={Java method API call for request latest sensor readings},label={lst:java_api_call}]
public void requestSensorValues(Response.Listener<APIResponse> listener,
Response.ErrorListener errorListener){
        Utils.methodDebug(LOGTAG);

	      //Create a Map for the HTTP headers
        Map<String, String> headers = new HashMap<String, String>();
        //Add the service for getting the latest sensor values
        headers.put(Constants.API_REQUEST_HEADER_SERVICE,
         Constants.API_REQUEST_SERVICE_GET_SENSOR_VALUES);

		    //Create the request object
        GsonRequest<APIResponse> sensorValueRequest = 
        new GsonRequest<APIResponse>(URL, APIResponse.class, 
        headers, listener, errorListener);
        
        //Add request to queue to be executed
        addToQueue(sensorValueRequest);
    }

\end{lstlisting}

\begin{lstlisting}[caption={APIResponse class, used when parsing the RESTful API response},label={lst:java_api_response_obj}]
public class APIResponse {
    //MetaData Params
    public int status_code;
    public String pi_public_ip;

    //Requested Objects
    public CurrentSensorValuesFromServer sensor_values;

}
\end{lstlisting}	

\subsubsection{Direct Communication}	
To provide direct communication from the Sensor Management System to the application, the Android device must be connected via the access point which is being administered by the Raspberry Pi. When pairing with the system, the application creates a multicast socket and joins the group, which the Sensor Management System is perpetually a member of. A pairing session object, encoded in JSON, is sent to the multicast channel from the application. The session object identifies the device and provides some general monitoring information. An example of this JSON session object can be seen in Listing~\ref{lst:json_device_connect} in Section~\ref{sssec:sms_direct_comm}, Sensor Management System Direct Communication. \\\\
On receiving this session object, the Sensor Management System performs the necessary pairing operations and sends back a status message, either verifying a successful connection, or failure. \\\\
Natively on Android multicast networking is switched off to reduce battery consumption. To perform multicast operations, a lock must be acquired from the operating system, seen in Listing~\ref{lst:java_multicast_lock}. Because of this limitation, the only multicast message sent from the application is the pairing session object, and after sending the multicast socket is closed, and the lock released. All further communication is handled via TCP sockets. This has the additional benefit of reliability.
\begin{lstlisting}[caption={Multicast lock acquisition},label={lst:java_multicast_lock}]
//Get the WifiManager service from the OS
WifiManager wifiManager = 
(WifiManager) context.getSystemService(Context.WIFI_SERVICE);
//Get the lock object from the WifiManager
WifiManager.MulticastLock lock = wifiManager.createMulticastLock(LOGTAG);
//Aquire the lock and begin multicast networking
lock.acquire();
\end{lstlisting}	
The singleton design pattern was applied to the object that was delegated the responsibility of communication between the application and the Sensor Management System. The object was entitled SocketManager, as its main duty is the orchestration of TCP/IP sockets. By maintaining a single point of interaction, the management of communication is straightforward. Overall application complexity is reduced as messages can be passed from any code location, without having the implementational overhead of passing the SocketManager object to each class which requires its use. \\\\
Below in Listing~\ref{lst:java_socket_send} is an example of a direct message to the Sensor Management System, in this case a new configuration is being sent. We simple utilise a static method, getInstance, on the SocketManager object, passing to it the Android application context, this returns the singleton object which can subsequently be used to send a direct message to the Sensor Management System. The sendMsgToPi method simply takes a JSON encoded string and sends it to the Raspberry Pi. 
\begin{lstlisting}[caption={Singleton SocketManager object send message method invocation},label={lst:java_socket_send}]
SocketManager.getInstance(getAppContext()).sndMsgToPi(Utils.toJson(newConfig);
\end{lstlisting}	

\noindent
The API call for sensor data is executed repeatedly every second. This is to ensure the latest values are displayed. This is not optimal, and in practise, would be unsuitable. All other API calls are either invoked when the "onResume" fragment lifecycle method is called, or issued at the event of user input. The "onResume" lifecycle method is invoked when the user navigates to a fragment. 


\newpage
\subsubsection{Push Notifications}
\label{sssec:android_push_notifications}
A number of steps are required to implement push notification alerting. Figure~\ref{fig:android_pn_interaction} shows the interaction between the 4 entities involved. 

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{"Push Notification Diagram".png}
\caption{Push notification interaction diagram}
\label{fig:android_pn_interaction}
\end{figure}

The steps involved are as follows:  
\begin{enumerate}
  \item Create a new project in the Google Cloud Developer Console
  \item Authorise the project to grant it access to the Google Cloud Messaging(GCM) Service
  \item Obtain the projects API Key, which is used for authentication when performing requests to the GCM server
  \item Perform in app registration of the device to the GCM server, which generated a unique device identification number. This must be stored persistently by the RESTful API and is used to target notifications to the specific device
  \item Extend a IntentService object within the app which will act as a daemon for receiving the notification payload from the GCM service
  \item Extend an Wakeful Broadcast Receiver object within the app which will wake the device up if it’s on standby mode, and display the notification to the user
  \item And the final step is to implement a program that performs the push notification request, via HTTP, to the GCM server, specifying the registration ids and the payload to be pushed to devices. This is accomplished by the Sensor Management System\rq s Alert Manager class. 
\end{enumerate}	

\noindent
After an alert threshold has been broken and a push notification has been sent from the Sensor Management System to the Android Application, the resulting event of receiving the notification can be seen in the Figure~\ref{fig:android_pn_displayed} below. A white popup box appears at the very top of the screen. This box will appear regardless of the current foreground application. 

\begin{figure}[H]
\centering
\includegraphics[width=14cm, height=12cm]{"pn_showing".png}
\caption{Push notification being displayed}
\label{fig:android_pn_displayed}
\end{figure}

\noindent
Android has a mechanism, called PendingIntent, for opening an application by touching a push notification. This allows users to navigate directly to the application which has performed the alerting. When the push notification above is clicked on, the application will open and display some context sensitive help regarding the current sensor value. This can be seen in Figure~\ref{fig:android_pn_help} below.

\begin{figure}[H]
\centering
\includegraphics[width=14cm, height=12cm]{"context_help_2".png}
\caption{Conrext sensitive help after touching push notification}
\label{fig:android_pn_help}
\end{figure}

\subsubsection{Context Sensitive Help}
Little indication of safety conditions is provided by the sensor readings alone. In order to provide them with genuine feedback on the current environment and their own safety, a small dataset of sensor specific safety metrics was gathered from the internet. The entire dataset can be seen in Appendix B, Section~\ref{sec:appendix_b}.

\subsubsection{Graphing}
Graphing is provided by an open source library call MPAndroidChart \footnote{https://github.com/PhilJay/MPAndroidChart}. This library provides a comprehensive range of charts, and a large amount of functionality, including touch scaling, real time graphing and animations. All graphing is designated to the Stats fragment within the application.\\\\
The application requests the graphing data from either the RESTful API, or directly from the Sensor Management System depending on the method of communication being utilized. All data aggregation is performed outside of the application. When a request for graphing data is executed, the respective RDBMS handles the aggregation via SQL query. This facilitates the generation of average, max and minimum values for each column. \\\\
Line charts were chosen as the most effective way of conveying the data to the user. All graphs are interactive, and allow the user to zoom in or out on specific areas. 

\newpage
\noindent
The Current Hour Sensor Readings chart, Figure~\ref{fig:android_current_hour_chart}, graphs the current hour sensor values. The Y-axis denoting the sensor value, while the X-axis marks time.
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, height=12cm]{"current_hour_graph".png}
\caption{Current hour sensor values line chart}
\label{fig:android_current_hour_chart}
\end{figure}

\newpage
\noindent
The Current Day Summary chart, Figure~\ref{fig:android_current_day_chart},  plots aggregated values for each hour the system has been active that day. 
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, height=12cm]{"current_day_sum".png}
\caption{Current day sensor values aggregated by hour line chart}
\label{fig:android_current_day_chart}
\end{figure}

\newpage
\noindent
The Complete Summary chart, Figure~\ref{fig:android_summary_day_chart},  graphs aggregated values for each day the system has been active.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, height=12cm]{"complete_sum_graph".png}
\caption{Summary of sensor values aggregated by day}
\label{fig:android_summary_day_chart}
\end{figure}

\newpage
\noindent
The motion detector sensor data is displayed in the Current Day Summary and the Complete Summary charts as a percentage. This acts as an activity measurement, providing the user with the level of activity for a given time. This data could be used for home automation. An example of motion graphed as a precentage can be seen in Figure~\ref{fig:android_summary_motion} below.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, height=12cm]{"motion_graph".png}
\caption{Motion graphed as a precentage}
\label{fig:android_summary_motion}
\end{figure}

\newpage
\subsubsection{Camera Control and Video Streaming}
The application provides image capture, streaming, and a gallery of images and videos previously captured. As describe in Section~\ref{sssec:api_video_and_image}, RESTful API Video Streaming and Image Capture, image capture and streaming is facilitated by means of a HTTP request to the RESTful API where a flag is set, and delivered to the Sensor Management System, where the desired operation is executed.

\begin{figure}[H]
\centering
\includegraphics[width=14cm, height=16cm]{"image_fragment".png}
\caption{Image fragment for controling camera operation}
\label{fig:android_camera_fragment}
\end{figure}

\noindent
When communicated via the RESTful API, all images and videos are stored server side and requested when the the user navigates to the Image fragment. All requested assets are cached, which is handled by the Volley Networking library. \\\\
When communicated directly via the AP, the application connects to the SFTP server that's running as a daemon process on the Raspberry Pi. Image and video files can then be transferred programmatically directly to the device’s internal storage, or more specifically the application’s private storage directory. When the user presses the refresh button, which can be seen in the Figure~\ref{fig:android_camera_fragment} above, an SFTP connection is made, and all new image and video files are transferred to the device. These file are then simply read from internal storage each time the user navigates to the Image fragment within the application. \\\\
Streaming and video playback are handled by the native Android VideoView API. A uniform resource identifier(URI) is passed to the VideoView, and in the case of a static video, depending on the communication medium, the URI is either a URL pointing to the video stored remotely on the RESTful API, or when directly communicating, a file location within internal device storage. The Android VideoView has the functionality to download and play a video file simultaneously. \\\\
When a request is made for a remote video stream, the URI given to the VideoView is the URL constructed from the Sensor Management System\rq s public IP address, and a predefined port number. The application polls this URL until the stream starts. 

\newpage
\subsubsection{System Configuration}
As described in the Section~\ref{sssec:sms_sys_config}, Sensor Management System Configuration, the JSON object notation is used to configure the system. The Control fragment within the application provides the user with an interface for altering configurations of the Sensor Management System. It was implemented as a form, with each section titled by the underlying system component it configures. 

\begin{figure}[H]
\centering
\includegraphics[width=14cm, height=16cm]{"config_1".png}
\caption{System Details, Sensor Manager, and Alert Manager configuration form fields}
\label{fig:android_config_1}
\end{figure}

\noindent
The System Details section, in Figure~\ref{fig:android_config_1} above,  allows the user to name the Sensor Management System, set its location, and GPS latitude and longitude values. \\\\
\noindent
The Sensor Manager section, in Figure~\ref{fig:android_config_1} above, handles the time interval, in seconds, at which the sensor data is written out to persistent storage. This affects the granularity of the data being provided to the charts in the Stats fragment.  A priority can also be set on the thread which executes the sensor data storage. \\\\
The Alert Manager section, in Figure~\ref{fig:android_config_1} above, provides the ability to turn on or off the camera, alert buzzer, push notifications, and lockdown mode. When the lockdown mode is active, if motion is detected, the camera will be activated and a push notification will be sent to the user. Switching from the default of image capture to video capture is also facilitated. 

\begin{figure}[H]
\centering
\includegraphics[width=14cm, height=7cm]{"config_2".png}
\caption{API Manger and Access Point Manager configuration form fields}
\label{fig:android_config_2}
\end{figure}

\noindent
The API Manager section, in Figure~\ref{fig:android_config_2} above, configures how often sensor values, and camera files are uploaded to the RESTful API. It also allows the user to set how often the system should check for new configurations.\\\\
The Access Point Manager section, in Figure~\ref{fig:android_config_2} above, sets the rate at which sensor values are sent to the application when directly communicating. \\\\

\begin{figure}[H]
\centering
\includegraphics[width=14cm, height=10cm]{"config_4".png}
\caption{Sensor configuration fields}
\label{fig:android_config_3}
\end{figure}

\noindent
Each sensor connected to the Sensor Management System is configurable by the user, including its alerting threshold, probe rate and priority. Sensors can also be turned on or off. This can be seen in Figures~\ref{fig:android_config_3} and~\ref{fig:android_config_4}.

\begin{figure}[H]
\centering
\includegraphics[width=14cm, height=10cm]{"config_3".png}
\caption{Sensor configuration fields}
\label{fig:android_config_4}
\end{figure}

\noindent
The form\rq s submit button can be seen at the bottom of Figure~\ref{fig:android_config_4}. This will execute the collection of form field data, and will format it as JSON. The subsequent action is dependant on the communication medium. If directly communicating, the configuration will be delivered straight to the Sensor Management System, and it will be reconfigured within 1 second. When communicating via the RESTful API, the new config file will be uploaded, and requested by the Sensor Management System at the time interval set by the API Manager in Figure~\ref{fig:android_config_2}.

\newpage
\section{Testing and Evaluation}
\subsection{Continuous Integration Testing}
Continuous integration(CI) was followed throughout the development phase of the project. The Git code version control system was utilised, which allows the creation and management of cloud based code repositories. \\\\
To perform CI, a local working copy of the code repository is maintained, this is then merged with the cloud based remote repository once changes have be implemented, tested and verified. In this way, a stable version of the software is always available and backed-up. The main benefit of this code versioning approach is that changes can be reverted. For example, if a problem is found in the system, the entire repository can be reverted to an earlier working version. Additionally, for every change committed to the remote repository, a description of the alterations can be included, providing a development log, an invaluable resource when when reviewing the codebase. 

\subsection{Verification}
Verification testing took place throughout the development phase of the project. This is the process of ensuring the system is built according to the requirements and design specifications. I worked closely with the functional and nonfunctional requirement specifications, trying to keep the system aligned with the core features previously defined. The following features present in the initial system specification were omitted from the implementation. \\\\
No device authorization mechanism was implemented. This was envisaged to provide a means of Android device privilege management. In the current implementation, all devices have total control over the system, with no central administrator. This in practise would not be a viable solution, as anyone, trusted or untrusted, could alter the operation of the Sensor Management System. Due to time constraints, I chose to leave this requirement out.\\\\
The original specification proposed the ability for easy inclusion and integration of any desired sensor module, this was not achieved. The idea I had devised was to allow the user to connect a sensor directly to the Raspberry Pi, specifying its name, type, and GPIO pin it was connected to, and then the system would dynamically adapt to manage this additional sensor. While this is feasible in terms of sensor management and integration in the circuit, an architectural limitation stopped the implementation of this type of dynamic inclusion. The limitation faced was with the data layer, specifically the non-dynamic schema of Relational Database Management Systems. While it is possible to programmatically alter the database and add or remove columns, the complexity of the data management layer would have increased drastically, limiting my development time elsewhere. An alternative to overcome this, would be to switch to a NoSQL database. The dynamic schema of a NoSQL database would easily facilitate the addition or removal of sensors. \\\\
Other than these two shortfalls of the implementation, the specification was largely achieved. 

\subsection{Operational Timing}
There are a multitude of operations being performed asynchronously in Sensor Management System. Due to the Raspberry Pi having only a single core, multithreading has not provided much improvement in timing, possibility even introducing a negative impact on system performance. Testing functionality execution times is difficult as race conditions are commonplace. To conduct operational timing testing, I simply altered the configuration file setting all timing intervals to 10 seconds, and recorded the debug printing logs of the system, deducing the mean task execution times from the differences between the configured time interval and the actual time of execution. \\\\
It was observed that the actual task execution timing varied by up to an additional 2 seconds on all operations. This variability in configured time interval compared to actual execution time is likely down to a race condition for processor utilisation. Table~\ref{table:testing_op_timings} displays core system operation timings in seconds. \\\\

\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{|| c | c ||} 
 \hline
 \textbf{Operation} & \textbf{Mean Execution Time in Seconds}  \\ [0.5ex] 
 \hline\hline
 Querying single sensor & 0.2 \\ 
 \hline
 Query all sensors and write values to persistent storage & 1 \\
 \hline
 Push notifications from the time of sending to receival & 10 \\
 \hline
 Uploading sensor data to the RESTful API & 0.5 \\ [1ex] 
 \hline
 Downloading data from the RESTful API & 0.6 \\ [1ex] 
 \hline
 Connecting directly via Android application & 4 \\ [1ex] 
 \hline
 Direct data transfer & 0.3 \\ [1ex] 
 \hline
 
\end{tabular}
\end{center}
\caption{Operation mean execution times in seconds}
\label{table:testing_op_timings}
\end{table}

\subsection{Performance and Stress Testing}
The system holds up reasonably well under moderate loads, however this is largely  depending on configured operational timing intervals. This was a difficult area to perform any conclusive tests in as the system\rq s performance is closely coupled with the limited hardware resources of the Raspberry Pi. With the added overhead of background services running on the Raspberry Pi, such as the SFTP server and the Access Point with DHCP server, the Sensor Management System has limited computational space to operate in. 
\\\\
I configured the Sensor Management System to perform all operations at a timing interval of 1 second, the minimum interval allowed to be set by the Android UI. I observed that database writes became slow and backlogged as system execution progressed over time. After 20 minutes of system operation the delay amounted to between 10 and 15 seconds. API calls became slower to execute, and as a result, data was transferred to the RESTful API at delays of 5 to 10 seconds. \\\\
The Sensor Management System was robust enough to continue operation, performing alerting when needed, and the camera remained fully operational. However all operations had a latency which only grew as the system execution progressed over time. I attempted to further reduce the time interval to 0.5 seconds, but the same latency conditions were observed, but were increasing at a more rapid pace. It was found that the Sensor Management System operates optimally when timing intervals are between 5 and 10 seconds. Preferably, system operations should be scheduled at varying timing intervals, dispersing computational load more gradually. \\\\
As the Peripheral Sensor System, running on the Intel Galileo, is simplistic in design and operation, it can handle a very high volume of operations a second. I've tested the send rate of sensor values from the Peripheral Sensing Node to the Sensor Management System up to a timing interval of 0.3 seconds, and it operates without any noticeable jittering. This really displays the level of computational power a Complex Instruction Set architecture has over a Reduced Instruction Set. \\\\
For the Android application, I performed all development and testing on an Asus Nexus 7 tablet, which has a 1.51GHz quad core processor and 2 GBs of RAM. Inbuilt in Android Studio is a memory usage visualization tool. The maximum RAM usage I experienced when testing the application was 80 MBs. The average was around 50 MBs. In comparison, the default clock application which is packaged with the Android OS has an average RAM usage of 21 MBs. On average the application performs moderately, with minimal latency detectable. However, when graphing sensor values, a drop in performance is sometimes experienced, dependent on the number of sensor readings to be plotted. 

\subsection{Failures}
In my opinion the most significant failure in the project was not being able to successfully implement the Wifi Direct infrastructure originally proposed. This would have allowed peer-2-peer communication directly with the system, while simultaneously maintaining a normal connection with local networking infrastructure. The overall functionality of the system would have been largely the same, but in terms of the Android application operation, Wifi Direct would have provided a more elegant solution with less scope for implementation errors. In general, low level networking on mobile devices is difficult to implement optimally. Instead of being able to use Android\rq s comprehensive Wifi Direct APIs, I had to implement all wireless networking functionality manually, which increased the development phase of the project considerably. The main repercussion of this meant that the Android device has to be connect to the Raspberry Pi\rq s access point in order to communicate directly. This forces the user off their own wifi connection and is a poor solution in terms of user experience. \\\\
Something I took away from this failure is that new technologies should only be included in a system\rq s architecture after a thorough feasibility analysis has taken place. Only after a concrete prototype has been implemented, should the technology be adopted. I made the mistake of basing a central component on an emerging technology which has not found mainstream usage yet. While Wifi Direct promises the functionality of Bluetooth, but at much greater speeds, without developer community support its inclusion in projects will remain a risk. 

\newpage
\section{Conclusions}
Overall I think the project succeeded. The main goals I wanted to achieve with the system from the very beginning were remote sensor readings, configuration and alerting. These were the things I focused on implementing with a high degree of attention, basing the entire system architecture predominantly on them. By taking development objectives in small increments I was able to prototype a system that was fully operational in less than 6 months. Some shortcuts were taken, and little protected variation was included in my implementation. If I was to continue working on the project, a large amount of functionality would have to be recoded to improve extensibility, and efficiency. It\rq s important to remember that the system is a prototype, and with the Raspberry Pi\rq s limited resources, it\rq s hard to differentiate resource limitations, and the system\rq s limitation. In terms of hardware, found the power and durability of the Raspberry Pi to be extraordinary. The board I developed the system on was 2 years old, and not once did it show signs of fault. The Intel Galileo is also a very capable device, but is not as easy to develop with. 
\\\\
With a large amount of technologies incorporated in the project, being able to manage and unify each one in an extensible way really challenged for me. The Git code versioning system was invaluable to me, and without it the project would simply not have been possible. 
\\\\
The main skills I obtained from working on this project are in the areas of software engineering and project management. As the project progressed the aspects of the system which were poorly implemented became more apparent. When going back to add new functionality, often my software was too specific, and not generic enough to be easily extensible. By having to critically review my code to deduce the most effective way of extending it really gave a good insight into how software should be designed to be robust and open to change. \\\\
In terms of project management, having to make design decisions everyday to ensure a final working piece of software was produce gave me experience in identifying the essential components in a system. The ability to quarantine the core structure of a system was a skill I acquired early in the project, and it stood to me throughout its duration. Focusing on the core modules first, ensured a rudimental system was implemented, with everything else developed incrementally, on top of this initial structure. In my opinion managing design and development in small iterations was the reason the project succeeded overall. This is the most important takeaway from the project, and is something I will maintain in all subsequent projects I encounter from now on. 
\subsection{Potential Improvements and Going Further}
A key aspect not addressed is the intelligent use of the data to automate other systems present in the home. For example, as the infrared motion detection sensor can anonymously monitor activity, the data could be used along with the temperature to schedule central heating for times when motion is highest, and temperature is low. Similarly, the system could switch off alerting services if someone is cooking, and then switch alerting back on once they have vacated the room. \\\\
The configurable nature of the system allows a lot of flexibility, but for the end user, this would result in more confusion than benefit. A better solution would be to introduce an intelligent agent within the system to automate its configuration to best suit its environment. This could be achieved by using aggregated sensor values to set alerting thresholds.\\\\
Introducing a duel alert monitoring system to improve safety protection. This would add to the original mechanism for sensor value alerting by introducing monitoring server side. This could proactively alert the user if early warning signs of danger occur. A prediction model could be learned from previously experienced events, and used to deduce the likelihood of potential dangers from current sensor values. \\\\	
Changing the direct communication interface from Wifi to Bluetooth would be an essential alteration to the current implementation. This would improve the system\rq s overall usability considerably, no longer requiring the user to connect directly to the system\rq s access point. \\\\
Security doesn’t feature in the current implementation. I chose to focus on developing the core functionality of the system, and did not get to spend development time on improving security. Going forward, security would have to take a central role. \\\\
The polling mechanism the Sensor Management System currently utilises for API communication is not very optimal. A better solution would be to implement a distributed publish-subscribe architecture server side, that could push out events as they occur. To accomplish this, the Raspberry Pi would be required to maintain a web server, something the current implementation could not withstand. However, with the latest Raspberry Pi model 2, this would be feasible. \\\\
Migrating to a NoSQL database system would improve system flexibility, and allow the dynamic inclusion of sensors. Moving forward, this is an essential change, providing the infrastructure to allow users to plug in new sensors at will.

\newpage
\section{Appendix A}
\label{sec:appendix_a}
The following wirigin diagrams are created using the Fritzing simulation tool~\footnote{http://fritzing.org/home/}.  


\begin{figure}[h!btp]
\centering
\includegraphics[width=\textwidth , height=.72\paperheight]{"schematic_rasp_pi".png}
\caption{Wiring diagram for Raspberry Pi running the Sensor Management System}
\label{fig:schematic_rasp_pi}
\end{figure}

\begin{figure}[h!btp]
\centering
\includegraphics[width=\textwidth , height=.74\paperheight]{"schematic_galileo".png}
\caption{Wiring diagram for Intel Galileo running the Peripheral Sensor System. Note that no Grove base shield is included in this diagram due to it not being available for use with Fritzing. }
\label{fig:schematic_galileo}
\end{figure}

\newpage
\section{Appendix B}
\label{sec:appendix_b}
Carbon monoxide context sensitive help table, taken from http://www.detectcarbonmonoxide.com/co-health-risks/.


\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{|| L{8cm} | c ||} 
 \hline
 \textbf{Feedback Text} & \textbf{Level in Pars Per Million(PPM)}  \\ [0.5ex] 
 \hline\hline
 Safe Level & 0 \\ 
 \hline
 Maximum legal level for the work place & 25 \\
 \hline
 Headache and Dizziness within 6 to 8 hours of constant exposure & 35 \\
 \hline
 Headache after 1 to 2 hours of constant exposure & 100 \\ [1ex] 
 \hline
 Dizziness, Nausea, Fatigue, Headache after 2 to 3 hours of constant exposure & 200 \\ [1ex] 
 \hline
 Nausea and Headache after 1 to 2 hours, life threatening in 3 hours. & 400 \\ [1ex] 
 \hline
 Dizziness, Nausea and Headache after 45 minutes, unconsciousness after 2 hours & 800 \\ [1ex] 
 \hline
 Dizziness, Nausea and Headache after 20 minutes, unconsciousness and possible death after 2 hours & 1600 \\ [1ex] 
 \hline
 Dizziness, Nausea and Headache after 5 to 10 minutes, unconsciousness and possible death after 15 minutes & 3200 \\ [1ex] 
 \hline
 Dizziness and Headache after 1 to 2 minutes, unconsciousness and possible death between 2 and 15 minutes & 6400 \\ [1ex] 
 \hline
 Danger of death in 1 to 3 minutes & 12800 \\ [1ex] 
 \hline
\end{tabular}
\end{center}
\caption{Carbon monoxide context sensitive help table}
\label{table:testing_op_timings}
\end{table}

\newpage
\noindent
Flammable gas context sensitive help table, http://inspectapedia.com/sickhouse/Gas\_ Exposure\_ Limits.php

\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{|| L{8cm} | c ||} 
 \hline
 \textbf{Feedback Text} & \textbf{Level in Pars Per Million(PPM)}  \\ [0.5ex] 
 \hline\hline
 Safe Level & 0 \\ 
 \hline
 Check gas appliances, potential leakage. Do not light any open flames. & 25 \\
 \hline
 Check gas appliances, potential leakage. Open all windows. Do not light any open flames & 50 \\
 \hline
 Open all windows and doors, leave building and contact Gas Networks Ireland on 1850 20 50 50 & 100 \\ [1ex] 
 \hline
\end{tabular}
\end{center}
\caption{Flammable gas context sensitive help table}
\label{table:testing_op_timings}
\end{table}

\noindent
Temperature context sensitive help table, taken from http://en.wikipedia.org/wiki/Orders\_ of\_ magnitude\_ (temperature)

\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{|| L{8cm} | c ||} 
 \hline
 \textbf{Feedback Text} & \textbf{Level in Celsius}  \\ [0.5ex] 
 \hline\hline
 Sub-zero, greatly increased risk of Pneumonia & Below 0 \\ 
 \hline
 Close to Freezing, increased risk of Pneumonia & 0 \\
 \hline
 Below recommended room temperature, turn on heating to decrease risk of Pneumonia & 10 \\
 \hline
 Regular room temperature & 20 \\ [1ex] 
 \hline
 Above recommend average room temperature & 30 \\ [1ex] 
 \hline
 Possible fire, perform safety checks & 40 \\ [1ex] 
 \hline
 Possible fire, time to exit the building & 50 \\ [1ex] 
 \hline
\end{tabular}
\end{center}
\caption{Temperature context sensitive help table}
\label{table:testing_op_timings}
\end{table}

\newpage
\noindent
Motion context sensitive help table.

\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{|| L{8cm} | c ||} 
 \hline
 \textbf{Feedback Text} & \textbf{Boolean}  \\ [0.5ex] 
 \hline\hline
 No motion currently being detected & 0 \\ 
 \hline
 Motion currently being detected! & 1 \\
 \hline
\end{tabular}
\end{center}
\caption{Motion context sensitive help table}
\label{table:testing_op_timings}
\end{table}

\noindent
Light Ccntext sensitive help table, taken from http://www.engineeringtoolbox.com/light\- level\- rooms\- d\_ 708.html

\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{|| L{8cm} | c ||} 
 \hline
 \textbf{Feedback Text} & \textbf{Level in LUX}  \\ [0.5ex] 
 \hline\hline
 Typical level for a moonless night & Below 0 \\ 
 \hline
 Typical level for a full moon on a clear night & 1 \\
 \hline
 Typical level around twilight period & 5 \\
 \hline
 Typical level family living room lights & 50 \\ [1ex] 
 \hline
 Typical level office building hallways/bath rooms & 80 \\ [1ex] 
 \hline
 Typical level for a dark overcast day & 100 \\ [1ex] 
 \hline
 Typical level for office lighting & 300 \\ [1ex] 
 \hline
 Typical level for sunset or sunrise on a clear day & 400 \\ [1ex] 
 \hline
 Typical level for overcast day, or TV studio lighting & 1000 \\ [1ex] 
 \hline
 Typical level for full daylight & 10000 \\ [1ex] 
 \hline
 Typical level for direct sunlight & 30000 \\ [1ex] 
 \hline
\end{tabular}
\end{center}
\caption{Light context sensitive help table}
\label{table:testing_op_timings}
\end{table}

\newpage
\section{Appendix C}
\label{sec:appendix_C}
All code is housed on GitHub, and is open-source. 

\begin{table}[H]
\def\arraystretch{2}% 
\begin{center}
 \begin{tabular}{|| L{6cm} | c ||} 
 \hline
 \textbf{System} & \textbf{URL of Repository}  \\ [0.5ex] 
 \hline\hline
 Sensor Management System and RESTful API & https://github.com/kpmmmurphy/FinalYearProject \\ 
 \hline
 Peripheral Sensing System & https://github.com/kpmmmurphy/FYPGalileo \\
 \hline
 Android Application & https://github.com/kpmmmurphy/FYP-Android-App/ \\
 \hline

\end{tabular}
\end{center}
\caption{Code repository URLs}
\label{table:testing_op_timings}
\end{table}

\end{document}
